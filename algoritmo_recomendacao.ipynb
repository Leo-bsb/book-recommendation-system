{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ“š Sistema de RecomendaÃ§Ã£o de Livros Inteligente"
      ],
      "metadata": {
        "id": "8g6eLmWGFuNn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ¯ VisÃ£o Geral do Projeto\n",
        "\n",
        "Este projeto implementa um **sistema hÃ­brido de recomendaÃ§Ã£o** que combina tÃ©cnicas colaborativas e baseadas em conteÃºdo para sugerir livros personalizados. Desenvolvido com PyTorch, o sistema analisa padrÃµes de avaliaÃ§Ã£o de usuÃ¡rios e caracterÃ­sticas dos livros para gerar recomendaÃ§Ãµes precisas e diversificadas.\n",
        "\n",
        "### ğŸ“Š Dataset Utilizado\n",
        "- **Fonte**: [GoodBooks-10k](https://github.com/zygmuntz/goodbooks-10k/tree/master)\n",
        "- **6 milhÃµes** de avaliaÃ§Ãµes de **10,000** livros por **53,424** usuÃ¡rios\n",
        "- Escala de ratings: 1-5 estrelas"
      ],
      "metadata": {
        "id": "LRfV1DWe7ET0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as pl\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "from collections import Counter\n",
        "import time\n",
        "\n",
        "# ConfiguraÃ§Ãµes de performance\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.set_float32_matmul_precision('high')\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"âœ… Bibliotecas importadas e configuradas\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egibktA9MajJ",
        "outputId": "4a3dc161-9b22-4d9c-c31d-a6a8b52fddcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Bibliotecas importadas e configuradas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ“¥ Carregamento e PreparaÃ§Ã£o dos Dados\n",
        "\n",
        "### ğŸ¯ EstratÃ©gia de Qualidade de Dados\n",
        "\n",
        "```python\n",
        "# Filtragem inteligente para melhor qualidade\n",
        "user_counts = df.group_by('user_id').agg(pl.count().alias('n_ratings'))\n",
        "book_counts = df.group_by('book_id').agg(pl.count().alias('n_ratings'))\n",
        "\n",
        "# Manter apenas usuÃ¡rios com â‰¥10 ratings e livros com â‰¥5 ratings\n",
        "df = df.join(user_counts.filter(pl.col('n_ratings') >= 10), on='user_id')\n",
        "df = df.join(book_counts.filter(pl.col('n_ratings') >= 5), on='book_id')\n",
        "```\n",
        "\n",
        "**DecisÃµes Tomadas**:\n",
        "- âœ… **Filtro de usuÃ¡rios ativos**: Remove usuÃ¡rios com poucas avaliaÃ§Ãµes\n",
        "- âœ… **Filtro de livros relevantes**: Elimina livros com poucas interaÃ§Ãµes\n",
        "- âœ… **NormalizaÃ§Ã£o de ratings**: Escala 0-1 para treino estÃ¡vel\n",
        "- âœ… **Split estratificado**: MantÃ©m distribuiÃ§Ã£o original das avaliaÃ§Ãµes\n",
        "\n",
        "**Resultado**: Dataset otimizado com **interaÃ§Ãµes significativas** e **qualidade garantida**"
      ],
      "metadata": {
        "id": "qXATFgOfCV64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ¯ CORREÃ‡ÃƒO CRÃTICA: EstratÃ©gia para alta precisÃ£o com diversidade\n",
        "try:\n",
        "    df = pl.read_csv('/content/ratings.csv')\n",
        "    books_df = pd.read_csv('/content/books.csv')\n",
        "    print(\"âœ… Arquivos carregados com sucesso\")\n",
        "\n",
        "    # ğŸ¯ ANÃLISE INICIAL DETALHADA\n",
        "    print(\"ğŸ“Š EstatÃ­sticas dos dados originais:\")\n",
        "    print(f\"Ratings - Min: {df['rating'].min()}, Max: {df['rating'].max()}, Mean: {df['rating'].mean():.3f}\")\n",
        "    print(f\"Dataset size: {len(df):,} interaÃ§Ãµes\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"âŒ Erro ao carregar arquivos: {e}\")\n",
        "    # Criar dados de exemplo mais realistas\n",
        "    print(\"ğŸ“ Criando dados de exemplo realistas...\")\n",
        "    n_users, n_books = 5000, 10000\n",
        "    # Simular distribuiÃ§Ã£o real de ratings (mais 4s e 5s)\n",
        "    ratings = np.random.choice([1, 2, 3, 4, 5], 50000, p=[0.05, 0.1, 0.2, 0.35, 0.3])\n",
        "\n",
        "    df = pl.DataFrame({\n",
        "        'user_id': np.random.randint(1, 5000, 50000),\n",
        "        'book_id': np.random.randint(1, 1000, 50000),\n",
        "        'rating': ratings.astype(np.float32)\n",
        "    })\n",
        "\n",
        "    books_df = pd.DataFrame({\n",
        "        'book_id': range(1, 1001),\n",
        "        'title': [f'Book {i}' for i in range(1, 1001)],\n",
        "        'authors': [f'Author {i}' for i in range(1, 1001)],\n",
        "        'average_rating': np.random.uniform(3.5, 4.8, 1000),\n",
        "        'ratings_count': np.random.randint(100, 50000, 1000)\n",
        "    })\n",
        "\n",
        "# ğŸ¯ OTIMIZAÃ‡ÃƒO: Filtrar dados para melhor qualidade\n",
        "print(\"\\nğŸ¯ Otimizando dados para treino...\")\n",
        "\n",
        "# Remover usuÃ¡rios e livros com poucas interaÃ§Ãµes\n",
        "user_counts = df.group_by('user_id').agg(pl.count().alias('n_ratings'))\n",
        "book_counts = df.group_by('book_id').agg(pl.count().alias('n_ratings'))\n",
        "\n",
        "# Manter apenas usuÃ¡rios com pelo menos 10 ratings e livros com pelo menos 5 ratings\n",
        "df = df.join(user_counts.filter(pl.col('n_ratings') >= 10), on='user_id')\n",
        "df = df.join(book_counts.filter(pl.col('n_ratings') >= 5), on='book_id')\n",
        "\n",
        "print(f\"ğŸ“Š Dados apÃ³s filtragem: {len(df):,} interaÃ§Ãµes\")\n",
        "\n",
        "# AnÃ¡lise inicial dos dados\n",
        "print(\"\\nğŸ“ˆ AnÃ¡lise dos IDs Ãºnicos:\")\n",
        "unique_counts = df.select([\n",
        "    pl.col(\"user_id\").n_unique().alias(\"unique_user_id\"),\n",
        "    pl.col(\"book_id\").n_unique().alias(\"unique_book_id\")\n",
        "])\n",
        "print(unique_counts)\n",
        "\n",
        "print(f\"\\nğŸ” CUDA disponÃ­vel: {torch.cuda.is_available()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76pYfuV5Ma-w",
        "outputId": "b53f6fa9-b725-42d0-f4ec-28e870490f06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Arquivos carregados com sucesso\n",
            "ğŸ“Š EstatÃ­sticas dos dados originais:\n",
            "Ratings - Min: 1, Max: 5, Mean: 3.920\n",
            "Dataset size: 5,976,479 interaÃ§Ãµes\n",
            "\n",
            "ğŸ¯ Otimizando dados para treino...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2090598338.py:38: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
            "  user_counts = df.group_by('user_id').agg(pl.count().alias('n_ratings'))\n",
            "/tmp/ipython-input-2090598338.py:39: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
            "  book_counts = df.group_by('book_id').agg(pl.count().alias('n_ratings'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š Dados apÃ³s filtragem: 5,976,479 interaÃ§Ãµes\n",
            "\n",
            "ğŸ“ˆ AnÃ¡lise dos IDs Ãºnicos:\n",
            "shape: (1, 2)\n",
            "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "â”‚ unique_user_id â”† unique_book_id â”‚\n",
            "â”‚ ---            â”† ---            â”‚\n",
            "â”‚ u32            â”† u32            â”‚\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
            "â”‚ 53424          â”† 10000          â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\n",
            "ğŸ” CUDA disponÃ­vel: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ—ï¸ Arquitetura do Sistema\n",
        "\n",
        "### ğŸ”„ Fluxo de Processamento\n",
        "\n",
        "```\n",
        "Dados Brutos â†’ Filtragem â†’ NormalizaÃ§Ã£o â†’ Treino do Modelo â†’ RecomendaÃ§Ãµes\n",
        "```\n",
        "\n",
        "### ğŸ“Š Estrutura de Dados\n",
        "\n",
        "| Componente | DescriÃ§Ã£o | PropÃ³sito |\n",
        "|------------|-----------|-----------|\n",
        "| **User-Item Matrix** | Matriz esparsa de avaliaÃ§Ãµes | Base para filtragem colaborativa |\n",
        "| **Embeddings** | RepresentaÃ§Ãµes vetoriais | Capturar padrÃµes latentes |\n",
        "| **Content Features** | Metadados dos livros | Enriquecer recomendaÃ§Ãµes |"
      ],
      "metadata": {
        "id": "1jCs1lXvCtjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ¯ PROCESSAMENTO DE DADOS OTIMIZADO\n",
        "print(\"\\nğŸ”„ Processando dados com normalizaÃ§Ã£o...\")\n",
        "\n",
        "# ConversÃ£o e casting\n",
        "df = df.with_columns([\n",
        "    pl.col(\"user_id\").cast(pl.Int32),  # ğŸ¯ Menos memÃ³ria\n",
        "    pl.col(\"book_id\").cast(pl.Int32),\n",
        "    pl.col(\"rating\").cast(pl.Float32)\n",
        "])\n",
        "\n",
        "# ğŸ¯ NORMALIZAÃ‡ÃƒO CRÃTICA DAS RATINGS\n",
        "rating_stats = df.select([\n",
        "    pl.col(\"rating\").mean().alias(\"mean\"),\n",
        "    pl.col(\"rating\").std().alias(\"std\"),\n",
        "    pl.col(\"rating\").min().alias(\"min\"),\n",
        "    pl.col(\"rating\").max().alias(\"max\")\n",
        "]).to_dicts()[0]\n",
        "\n",
        "print(f\"ğŸ“Š EstatÃ­sticas das ratings: Î¼={rating_stats['mean']:.3f}, Ïƒ={rating_stats['std']:.3f}\")\n",
        "\n",
        "# Normalizar ratings para treino (0-1 scale)\n",
        "df = df.with_columns([\n",
        "    ((pl.col(\"rating\") - rating_stats['min']) /\n",
        "     (rating_stats['max'] - rating_stats['min'])).alias(\"rating_norm\")\n",
        "])\n",
        "\n",
        "# ExtraÃ§Ã£o de IDs Ãºnicos\n",
        "user_ids = df.select(pl.col(\"user_id\")).unique().to_series().to_list()\n",
        "book_ids = df.select(pl.col(\"book_id\")).unique().to_series().to_list()\n",
        "\n",
        "print(f\"ğŸ‘¥ UsuÃ¡rios Ãºnicos: {len(user_ids):,}\")\n",
        "print(f\"ğŸ“š Livros Ãºnicos: {len(book_ids):,}\")\n",
        "\n",
        "# Mapeamentos\n",
        "user2idx = {uid: i for i, uid in enumerate(user_ids)}\n",
        "book2idx = {bid: i for i, bid in enumerate(book_ids)}\n",
        "idx2book = {i: bid for i, bid in enumerate(book_ids)}\n",
        "\n",
        "# ConversÃ£o para Pandas\n",
        "df_pandas = df.to_pandas()\n",
        "\n",
        "# ğŸ¯ CORREÃ‡ÃƒO: Usar ratings normalizadas para treino\n",
        "df_pandas['user_idx'] = df_pandas['user_id'].map(user2idx)\n",
        "df_pandas['book_idx'] = df_pandas['book_id'].map(book2idx)\n",
        "\n",
        "print(f\"ğŸ‘¥ n_users = {len(user2idx)}, user_idx max = {df_pandas['user_idx'].max()}\")\n",
        "print(f\"ğŸ“š n_books = {len(book2idx)}, book_idx max = {df_pandas['book_idx'].max()}\")\n",
        "\n",
        "# ğŸ¯ SPLIT ESTRATIFICADO MELHORADO\n",
        "train_df, test_df = train_test_split(\n",
        "    df_pandas,\n",
        "    test_size=0.05,\n",
        "    random_state=42,\n",
        "    stratify=pd.cut(df_pandas['rating'], bins=5)\n",
        ")\n",
        "\n",
        "print(f\"ğŸ“š Dados de treino: {len(train_df):,}\")\n",
        "print(f\"ğŸ“š Dados de teste: {len(test_df):,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGtFmfHDMcCt",
        "outputId": "eea9a56a-2c49-4c1c-e45f-5428568b8b39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”„ Processando dados com normalizaÃ§Ã£o...\n",
            "ğŸ“Š EstatÃ­sticas das ratings: Î¼=3.920, Ïƒ=0.991\n",
            "ğŸ‘¥ UsuÃ¡rios Ãºnicos: 53,424\n",
            "ğŸ“š Livros Ãºnicos: 10,000\n",
            "ğŸ‘¥ n_users = 53424, user_idx max = 53423\n",
            "ğŸ“š n_books = 10000, book_idx max = 9999\n",
            "ğŸ“š Dados de treino: 5,677,655\n",
            "ğŸ“š Dados de teste: 298,824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ¯ DATASET COM NORMALIZAÃ‡ÃƒO\n",
        "class BookRatingDataset(Dataset):\n",
        "    def __init__(self, df, use_normalized=True):\n",
        "        self.users = torch.from_numpy(df[\"user_idx\"].values).long()\n",
        "        self.items = torch.from_numpy(df[\"book_idx\"].values).long()\n",
        "        # ğŸ¯ Usar ratings normalizadas para treino\n",
        "        if use_normalized and 'rating_norm' in df.columns:\n",
        "            self.ratings = torch.from_numpy(df[\"rating_norm\"].values).float()\n",
        "        else:\n",
        "            self.ratings = torch.from_numpy(df[\"rating\"].values).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ratings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.users[idx], self.items[idx], self.ratings[idx]\n",
        "\n",
        "# Dispositivo\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"ğŸ–¥ï¸  Usando dispositivo: {device}\")\n",
        "\n",
        "# Datasets e DataLoaders\n",
        "train_ds = BookRatingDataset(train_df, use_normalized=True)\n",
        "test_ds = BookRatingDataset(test_df, use_normalized=True)\n",
        "\n",
        "batch_size = 16384 if torch.cuda.is_available() else 4096  # ğŸ¯ Batch menor para melhor estabilidade\n",
        "num_workers = 2 if torch.cuda.is_available() else 0\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
        "                     num_workers=num_workers, pin_memory=True)\n",
        "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=False,\n",
        "                    num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "print(f\"ğŸ“¦ Batch size: {batch_size}, Workers: {num_workers}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIYe1HwqMdve",
        "outputId": "4670af3a-0a62-43dc-bd7c-84ee94c73cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ–¥ï¸  Usando dispositivo: cuda\n",
            "ğŸ“¦ Batch size: 16384, Workers: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ¯ MODELO AVANÃ‡ADO COM REGULARIZAÃ‡ÃƒO\n",
        "class AdvancedMatrixFactorization(nn.Module):\n",
        "    def __init__(self, n_users, n_items, n_factors=64, dropout_rate=0.3):\n",
        "        super().__init__()\n",
        "        # ğŸ¯ Menos fatores para evitar overfitting\n",
        "        self.user_emb = nn.Embedding(n_users, n_factors)\n",
        "        self.item_emb = nn.Embedding(n_items, n_factors)\n",
        "        self.user_bias = nn.Embedding(n_users, 1)\n",
        "        self.item_bias = nn.Embedding(n_items, 1)\n",
        "        self.global_bias = nn.Parameter(torch.tensor([0.0]))\n",
        "\n",
        "        # ğŸ¯ Camadas adicionais para complexidade controlada\n",
        "        self.hidden = nn.Sequential(\n",
        "            nn.Linear(n_factors, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(32, 16),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.output_layer = nn.Linear(16, 1)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        # ğŸ¯ InicializaÃ§Ã£o mais conservadora\n",
        "        nn.init.xavier_uniform_(self.user_emb.weight)\n",
        "        nn.init.xavier_uniform_(self.item_emb.weight)\n",
        "        nn.init.constant_(self.user_bias.weight, 0.01)\n",
        "        nn.init.constant_(self.item_bias.weight, 0.01)\n",
        "\n",
        "    def forward(self, user_idx, item_idx):\n",
        "        user_vec = self.user_emb(user_idx)\n",
        "        item_vec = self.item_emb(item_idx)\n",
        "\n",
        "        # ğŸ¯ InteraÃ§Ã£o mais sofisticada\n",
        "        interaction = user_vec * item_vec\n",
        "        hidden_out = self.hidden(interaction)\n",
        "        prediction = self.output_layer(hidden_out).squeeze()\n",
        "\n",
        "        user_b = self.user_bias(user_idx).squeeze()\n",
        "        item_b = self.item_bias(item_idx).squeeze()\n",
        "\n",
        "        return prediction + user_b + item_b + self.global_bias\n",
        "\n",
        "# InstanciaÃ§Ã£o do modelo\n",
        "n_users = len(user_ids)\n",
        "n_items = len(book_ids)\n",
        "\n",
        "model = AdvancedMatrixFactorization(\n",
        "    n_users,\n",
        "    n_items,\n",
        "    n_factors=64,  # ğŸ¯ Menos fatores para generalizaÃ§Ã£o\n",
        "    dropout_rate=0.3,  # ğŸ¯ Mais dropout para regularizaÃ§Ã£o\n",
        ").to(device)\n",
        "\n",
        "print(f\"ğŸ§  ParÃ¢metros do modelo: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "# ğŸ¯ OTIMIZADOR COM CONFIGURAÃ‡ÃƒO CONSERVADORA\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)  # ğŸ¯ Mais weight decay\n",
        "loss_fn = nn.MSELoss()\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)  # ğŸ¯ Scheduler melhor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDsx4oRMMfbR",
        "outputId": "2575a77b-9f28-48af-b4f8-a879c580057c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  ParÃ¢metros do modelo: 4,125,186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FunÃ§Ãµes de treino otimizadas\n",
        "def train_epoch(model, dataloader, optimizer, loss_fn):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for users, items, ratings in dataloader:\n",
        "        users = users.to(device, non_blocking=True)\n",
        "        items = items.to(device, non_blocking=True)\n",
        "        ratings = ratings.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        preds = model(users, items)\n",
        "        loss = loss_fn(preds, ratings)\n",
        "        loss.backward()\n",
        "\n",
        "        # ğŸ¯ Gradient clipping mais agressivo\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * len(ratings)\n",
        "    return total_loss / len(dataloader.dataset)\n",
        "\n",
        "def evaluate(model, dataloader, loss_fn):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for users, items, ratings in dataloader:\n",
        "            users = users.to(device, non_blocking=True)\n",
        "            items = items.to(device, non_blocking=True)\n",
        "            ratings = ratings.to(device, non_blocking=True)\n",
        "\n",
        "            preds = model(users, items)\n",
        "            # ğŸ¯ Converter prediÃ§Ãµes normalizadas de volta para escala original\n",
        "            preds_denorm = preds * (rating_stats['max'] - rating_stats['min']) + rating_stats['min']\n",
        "            ratings_denorm = ratings * (rating_stats['max'] - rating_stats['min']) + rating_stats['min']\n",
        "\n",
        "            loss = loss_fn(preds_denorm, ratings_denorm)\n",
        "            total_loss += loss.item() * len(ratings)\n",
        "    return total_loss / len(dataloader.dataset)\n",
        "\n",
        "def mean_absolute_error(model, dataloader):\n",
        "    model.eval()\n",
        "    total_abs_error = 0\n",
        "    with torch.no_grad():\n",
        "        for users, items, ratings in dataloader:\n",
        "            users = users.to(device, non_blocking=True)\n",
        "            items = items.to(device, non_blocking=True)\n",
        "            ratings = ratings.to(device, non_blocking=True)\n",
        "\n",
        "            preds = model(users, items)\n",
        "            # ğŸ¯ Converter para escala original para cÃ¡lculo do MAE\n",
        "            preds_denorm = preds * (rating_stats['max'] - rating_stats['min']) + rating_stats['min']\n",
        "            ratings_denorm = ratings * (rating_stats['max'] - rating_stats['min']) + rating_stats['min']\n",
        "\n",
        "            total_abs_error += torch.abs(preds_denorm - ratings_denorm).sum().item()\n",
        "    return total_abs_error / len(dataloader.dataset)"
      ],
      "metadata": {
        "id": "Wa-eu-TqMhEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ğŸ§  Modelo de FatorizaÃ§Ã£o de Matriz AvanÃ§ado\n",
        "\n",
        "### ğŸ—ï¸ Arquitetura Neural\n",
        "\n",
        "```python\n",
        "class AdvancedMatrixFactorization(nn.Module):\n",
        "    def __init__(self, n_users, n_items, n_factors=64, dropout_rate=0.3):\n",
        "        self.user_emb = nn.Embedding(n_users, n_factors)    # ğŸ¯ Embedding de usuÃ¡rios\n",
        "        self.item_emb = nn.Embedding(n_items, n_factors)    # ğŸ“š Embedding de livros\n",
        "        self.hidden = nn.Sequential(                        # ğŸ§  Camadas ocultas\n",
        "            nn.Linear(n_factors, 32), nn.ReLU(), nn.Dropout(dropout_rate),\n",
        "            nn.Linear(32, 16), nn.ReLU()\n",
        "        )\n",
        "```\n",
        "\n",
        "### ğŸ¯ Metodologias Implementadas\n",
        "\n",
        "#### 1. **Filtragem Colaborativa (User-Based)**\n",
        "- Analisa **padrÃµes de usuÃ¡rios similares**\n",
        "- Baseada nas avaliaÃ§Ãµes histÃ³ricas\n",
        "- **Vantagem**: Descobre interesses implÃ­citos\n",
        "\n",
        "#### 2. **Filtragem Baseada em ConteÃºdo (Item-Based)**\n",
        "- Utiliza **metadados dos livros** (tÃ­tulo, autor, popularidade)\n",
        "- **Score de qualidade**: Combina rating mÃ©dio e nÃºmero de avaliaÃ§Ãµes\n",
        "- **Score de descoberta**: Incentiva livros menos conhecidos\n",
        "\n",
        "#### 3. **Abordagem HÃ­brida** â­\n",
        "```python\n",
        "# CombinaÃ§Ã£o dos scores\n",
        "final_scores = cf_scores * 0.9 + quality_scores * 0.1\n",
        "```"
      ],
      "metadata": {
        "id": "_WXXWW1TC_MH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ¯ TREINO COM MONITORAMENTO APRIMORADO\n",
        "epochs = 15\n",
        "best_val_mae = float('inf')\n",
        "patience = 4\n",
        "epochs_no_improve = 0\n",
        "best_model_state = None\n",
        "\n",
        "print(\"ğŸš€ Iniciando treino do modelo OTIMIZADO...\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss = train_epoch(model, train_dl, optimizer, loss_fn)\n",
        "    val_loss = evaluate(model, test_dl, loss_fn)\n",
        "    val_mae = mean_absolute_error(model, test_dl)\n",
        "\n",
        "    scheduler.step()\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "    # ğŸ¯ MÃ©tricas em escala original\n",
        "    train_rmse_orig = (train_loss ** 0.5) * (rating_stats['max'] - rating_stats['min'])\n",
        "    val_rmse_orig = (val_loss ** 0.5) * (rating_stats['max'] - rating_stats['min'])\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Train RMSE: {train_rmse_orig:.4f} - Val RMSE: {val_rmse_orig:.4f} - Val MAE: {val_mae:.4f} - LR: {current_lr:.6f}\")\n",
        "\n",
        "    if val_mae < best_val_mae:\n",
        "        best_val_mae = val_mae\n",
        "        epochs_no_improve = 0\n",
        "        best_model_state = model.state_dict().copy()\n",
        "        print(f\"âœ… NOVO RECORDE - Val MAE: {val_mae:.4f}\")\n",
        "\n",
        "        # ğŸ¯ Salvar checkpoint do melhor modelo\n",
        "        torch.save(best_model_state, 'best_model.pth')\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        print(f\"â³ Sem melhoria hÃ¡ {epochs_no_improve}/{patience} Ã©pocas\")\n",
        "\n",
        "    if epochs_no_improve >= patience:\n",
        "        print(f\"ğŸš« Early stopping ativado\")\n",
        "        break\n",
        "\n",
        "# Carregar melhor modelo\n",
        "if best_model_state is not None:\n",
        "    model.load_state_dict(best_model_state)\n",
        "    print(f\"ğŸ¯ Melhor modelo carregado - Val MAE: {best_val_mae:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r9WawymMi6h",
        "outputId": "f895a8c1-9488-401e-d235-be13dfdf66b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Iniciando treino do modelo OTIMIZADO...\n",
            "Epoch 1/15 - Train RMSE: 1.3373 - Val RMSE: 3.3883 - Val MAE: 0.6674 - LR: 0.000976\n",
            "âœ… NOVO RECORDE - Val MAE: 0.6674\n",
            "Epoch 2/15 - Train RMSE: 0.7992 - Val RMSE: 3.2471 - Val MAE: 0.6273 - LR: 0.000905\n",
            "âœ… NOVO RECORDE - Val MAE: 0.6273\n",
            "Epoch 3/15 - Train RMSE: 0.6899 - Val RMSE: 3.3272 - Val MAE: 0.6383 - LR: 0.000794\n",
            "â³ Sem melhoria hÃ¡ 1/4 Ã©pocas\n",
            "Epoch 4/15 - Train RMSE: 0.6052 - Val RMSE: 3.4486 - Val MAE: 0.6616 - LR: 0.000655\n",
            "â³ Sem melhoria hÃ¡ 2/4 Ã©pocas\n",
            "Epoch 5/15 - Train RMSE: 0.5500 - Val RMSE: 3.5352 - Val MAE: 0.6793 - LR: 0.000500\n",
            "â³ Sem melhoria hÃ¡ 3/4 Ã©pocas\n",
            "Epoch 6/15 - Train RMSE: 0.5101 - Val RMSE: 3.6048 - Val MAE: 0.6936 - LR: 0.000345\n",
            "â³ Sem melhoria hÃ¡ 4/4 Ã©pocas\n",
            "ğŸš« Early stopping ativado\n",
            "ğŸ¯ Melhor modelo carregado - Val MAE: 0.6273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸš€ Processo de Treino e OtimizaÃ§Ã£o\n",
        "\n",
        "### âš™ï¸ ConfiguraÃ§Ãµes de Treino\n",
        "\n",
        "| ParÃ¢metro | Valor | Justificativa |\n",
        "|-----------|-------|---------------|\n",
        "| **Batch Size** | 16,384 (GPU) / 4,096 (CPU) | MÃ¡ximo desempenho |\n",
        "| **Learning Rate** | 0.001 | ConvergÃªncia estÃ¡vel |\n",
        "| **Weight Decay** | 0.01 | PrevenÃ§Ã£o de overfitting |\n",
        "| **Early Stopping** | 4 Ã©pocas | Evitar overfitting |\n",
        "\n",
        "### ğŸ“ˆ MÃ©tricas de AvaliaÃ§Ã£o\n",
        "\n",
        "```python\n",
        "# MAE na escala original (1-5 estrelas)\n",
        "def mean_absolute_error(model, dataloader):\n",
        "    preds_denorm = preds * (rating_stats['max'] - rating_stats['min']) + rating_stats['min']\n",
        "    ratings_denorm = ratings * (rating_stats['max'] - rating_stats['min']) + rating_stats['min']\n",
        "    return torch.abs(preds_denorm - ratings_denorm).mean()\n",
        "```\n",
        "\n",
        "**Resultados Esperados**:\n",
        "- âœ… **MAE**: 0.6-0.8 (erro mÃ©dio de 0.6-0.8 estrelas)\n",
        "- âœ… **Diversidade**: 70-80% (recomendaÃ§Ãµes variadas)\n",
        "- âœ… **Coverage**: Amplo catÃ¡logo de livros recomendados"
      ],
      "metadata": {
        "id": "_ObcVK-ADMoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ¯ PREPARAÃ‡ÃƒO DE DADOS DE CONTEÃšDO\n",
        "try:\n",
        "    books_content_df = books_df.copy()\n",
        "\n",
        "    if 'average_rating' in books_content_df.columns and 'ratings_count' in books_content_df.columns:\n",
        "        # ğŸ¯ Score de qualidade balanceado\n",
        "        books_content_df['quality_score'] = (\n",
        "            books_content_df['average_rating'] *\n",
        "            np.log1p(books_content_df['ratings_count']) *\n",
        "            (1 + 0.3 * (books_content_df['average_rating'] > 4.2))\n",
        "        )\n",
        "\n",
        "        # ğŸ¯ Score de \"descoberta\" suave\n",
        "        books_content_df['discovery_score'] = (\n",
        "            1.0 / (1.0 + np.log1p(books_content_df['ratings_count']) / 15.0)\n",
        "        )\n",
        "\n",
        "        books_content_df['quality_score'] = (\n",
        "            (books_content_df['quality_score'] - books_content_df['quality_score'].min()) /\n",
        "            (books_content_df['quality_score'].max() - books_content_df['quality_score'].min())\n",
        "        )\n",
        "\n",
        "        quality_scores_dict = books_content_df.set_index('book_id')['quality_score'].to_dict()\n",
        "        discovery_scores_dict = books_content_df.set_index('book_id')['discovery_score'].to_dict()\n",
        "\n",
        "        print(\"âœ… Sistema hÃ­brido com scores balanceados ativado\")\n",
        "    else:\n",
        "        print(\"âš ï¸  Usando sistema colaborativo puro\")\n",
        "        quality_scores_dict = {}\n",
        "        discovery_scores_dict = {}\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸  Erro nos dados de conteÃºdo: {e}\")\n",
        "    quality_scores_dict = {}\n",
        "    discovery_scores_dict = {}\n",
        "\n",
        "# ğŸ¯ ANÃLISE REAL DA DISTRIBUIÃ‡ÃƒO DE DADOS (SIMPLIFICADA)\n",
        "def analyze_real_distribution():\n",
        "    \"\"\"Analisa distribuiÃ§Ã£o real para definir thresholds corretos\"\"\"\n",
        "    print(\"ğŸ“Š ANALISANDO DISTRIBUIÃ‡ÃƒO REAL DOS DADOS...\")\n",
        "\n",
        "    # Popularidade real dos livros\n",
        "    book_popularity = df_pandas['book_id'].value_counts()\n",
        "\n",
        "    print(f\"ğŸ“š EstatÃ­sticas de Popularidade:\")\n",
        "    print(f\"   Total de livros: {len(book_popularity):,}\")\n",
        "    print(f\"   MÃ­nimo: {book_popularity.min()} avaliaÃ§Ãµes\")\n",
        "    print(f\"   MÃ¡ximo: {book_popularity.max():,} avaliaÃ§Ãµes\")\n",
        "    print(f\"   Mediana: {book_popularity.median():.0f} avaliaÃ§Ãµes\")\n",
        "    print(f\"   MÃ©dia: {book_popularity.mean():.1f} avaliaÃ§Ãµes\")\n",
        "\n",
        "    # Percentis reais (apenas para cÃ¡lculo interno)\n",
        "    percentis = np.percentile(book_popularity, [10, 25, 50, 75, 90, 95])\n",
        "\n",
        "    return percentis\n",
        "\n",
        "# Executar anÃ¡lise\n",
        "real_percentiles = analyze_real_distribution()\n",
        "\n",
        "# ğŸ¯ CRIAR MAPEAMENTO DE LIVROS\n",
        "def create_book_mapping():\n",
        "    \"\"\"Cria o mapeamento de book_id para tÃ­tulo e autor\"\"\"\n",
        "    global book_id_to_title_author\n",
        "\n",
        "    book_id_to_title_author = {}\n",
        "    try:\n",
        "        for _, row in books_df.iterrows():\n",
        "            book_id = row['book_id']\n",
        "            title = row.get('title', f'Book {book_id}')\n",
        "            authors = row.get('authors', 'Unknown Author')\n",
        "            book_id_to_title_author[book_id] = f\"{title} - {authors}\"\n",
        "        print(f\"âœ… Mapeamento de livros criado: {len(book_id_to_title_author)} entradas\")\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸  Erro ao criar mapeamento de livros: {e}\")\n",
        "        for bid in book_ids:\n",
        "            book_id_to_title_author[bid] = f\"Book {bid} - Unknown Author\"\n",
        "\n",
        "# Criar mapeamento\n",
        "create_book_mapping()\n"
      ],
      "metadata": {
        "id": "jymh9sV3D5yS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c30d47dc-bb2f-4013-a88f-a947f660c734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Sistema hÃ­brido com scores balanceados ativado\n",
            "ğŸ“Š ANALISANDO DISTRIBUIÃ‡ÃƒO REAL DOS DADOS...\n",
            "ğŸ“š EstatÃ­sticas de Popularidade:\n",
            "   Total de livros: 10,000\n",
            "   MÃ­nimo: 8 avaliaÃ§Ãµes\n",
            "   MÃ¡ximo: 22,806 avaliaÃ§Ãµes\n",
            "   Mediana: 248 avaliaÃ§Ãµes\n",
            "   MÃ©dia: 597.6 avaliaÃ§Ãµes\n",
            "âœ… Mapeamento de livros criado: 10000 entradas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ¯ Sistema de RecomendaÃ§Ã£o HÃ­brido\n",
        "\n",
        "### ğŸ”§ Mecanismos de DiversificaÃ§Ã£o\n",
        "\n",
        "#### 1. **Balanceamento de Popularidade**\n",
        "```python\n",
        "# Penalidade para livros super populares (top 10%)\n",
        "super_popular_mask = popularity_scores >= pop_percentiles[4]\n",
        "final_scores[super_popular_mask] -= diversity_strength * 0.3\n",
        "\n",
        "# Boost para \"gems escondidos\" (25% menos populares)\n",
        "hidden_gems_mask = (popularity_scores <= pop_percentiles[1]) & (popularity_scores > 0)\n",
        "final_scores[hidden_gems_mask] += discovery_boost * 0.4\n",
        "```\n",
        "\n",
        "#### 2. **DetecÃ§Ã£o de Interesses**\n",
        "```python\n",
        "categories = {\n",
        "    'ğŸ§™â€â™‚ï¸ Fantasia Ã‰pica': ['harry potter', 'game of thrones', ...],\n",
        "    'ğŸ”¬ FicÃ§Ã£o CientÃ­fica': ['science fiction', 'sci-fi', ...],\n",
        "    'â¤ï¸ Romance ContemporÃ¢neo': ['romance', 'love story', ...],\n",
        "    # ... 7 categorias adicionais\n",
        "}\n",
        "```\n",
        "\n",
        "#### 3. **EstratÃ©gia de SeleÃ§Ã£o Inteligente**\n",
        "- **Prioridade 1**: Top 2 livros (melhor personalizaÃ§Ã£o)\n",
        "- **Prioridade 2**: 2 livros diversificados (baixa frequÃªncia)\n",
        "- **Prioridade 3**: 1 livro de alta qualidade (balanceamento)"
      ],
      "metadata": {
        "id": "k8dpm0LuDfHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ¯ DETECÃ‡ÃƒO DE INTERESSES MELHORADA\n",
        "def detect_user_interests(user_original_id):\n",
        "    \"\"\"DetecÃ§Ã£o mais precisa e diversificada de interesses\"\"\"\n",
        "    if user_original_id not in user2idx:\n",
        "        return \"Interesses nÃ£o disponÃ­veis\"\n",
        "\n",
        "    user_ratings = df_pandas[df_pandas['user_id'] == user_original_id]\n",
        "\n",
        "    if len(user_ratings) == 0:\n",
        "        return \"Sem histÃ³rico suficiente\"\n",
        "\n",
        "    categories = {\n",
        "        'ğŸ§™â€â™‚ï¸ Fantasia Ã‰pica': ['harry potter', 'game of thrones', 'lord of the rings', 'wheel of time', 'dragon', 'magic'],\n",
        "        'ğŸ”¬ FicÃ§Ã£o CientÃ­fica': ['science fiction', 'sci-fi', 'space', 'dystopian', 'cyberpunk', 'alien'],\n",
        "        'â¤ï¸ Romance ContemporÃ¢neo': ['romance', 'love story', 'chick lit', 'relationship', 'contemporary'],\n",
        "        'â›ª Literatura Religiosa': ['bible', 'god', 'christian', 'prayer', 'faith', 'jesus', 'theology'],\n",
        "        'ğŸ›ï¸ HistÃ³ria & PolÃ­tica': ['history', 'political', 'constitution', 'declaration', 'war', 'government', 'biography'],\n",
        "        'ğŸ­ Drama & ClÃ¡ssicos': ['drama', 'classic', 'literary fiction', 'shakespeare', 'dickens'],\n",
        "        'ğŸ˜Š Humor & Graphic Novels': ['calvin and hobbes', 'graphic novel', 'comic', 'manga', 'humor', 'funny'],\n",
        "        'ğŸ” MistÃ©rio & Suspense': ['mystery', 'thriller', 'suspense', 'crime', 'detective'],\n",
        "        'ğŸŒˆ Young Adult': ['young adult', 'ya fiction', 'teen', 'coming of age'],\n",
        "        'ğŸŒ NÃ£o-FicÃ§Ã£o': ['feminist', 'essay', 'philosophy', 'science', 'sociology']\n",
        "    }\n",
        "\n",
        "    user_book_ids = user_ratings['book_id'].tolist()\n",
        "    user_titles = []\n",
        "\n",
        "    for book_id in user_book_ids:\n",
        "        title = book_id_to_title_author.get(book_id, \"\").lower()\n",
        "        user_titles.append(title)\n",
        "\n",
        "    category_scores = {}\n",
        "    for category, keywords in categories.items():\n",
        "        score = 0\n",
        "        matched_books = set()\n",
        "\n",
        "        for title in user_titles:\n",
        "            for keyword in keywords:\n",
        "                if keyword in title and title not in matched_books:\n",
        "                    score += 1\n",
        "                    matched_books.add(title)\n",
        "                    break\n",
        "        category_scores[category] = score\n",
        "\n",
        "    valid_categories = [(cat, score) for cat, score in category_scores.items() if score > 0]\n",
        "\n",
        "    if not valid_categories:\n",
        "        return \"Interesses diversos\"\n",
        "\n",
        "    valid_categories.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    if len(valid_categories) <= 3:\n",
        "        return \" | \".join([cat for cat, _ in valid_categories])\n",
        "\n",
        "    selected_categories = []\n",
        "    primary_categories = valid_categories[:2]\n",
        "\n",
        "    remaining = valid_categories[2:]\n",
        "    if remaining:\n",
        "        diverse_category = max(remaining, key=lambda x: x[1])\n",
        "        selected_categories = [cat for cat, _ in primary_categories] + [diverse_category[0]]\n",
        "    else:\n",
        "        selected_categories = [cat for cat, _ in primary_categories]\n",
        "\n",
        "    return \" | \".join(selected_categories)\n",
        "\n",
        "# ğŸ¯ FUNÃ‡ÃƒO DE RECOMENDAÃ‡ÃƒO HÃBRIDA CORRIGIDA\n",
        "def hybrid_recommend_books(user_original_id, top_n=5, diversity_strength=0.8, discovery_boost=0.5):\n",
        "    \"\"\"RecomendaÃ§Ã£o balanceada entre personalizaÃ§Ã£o e diversidade\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    if user_original_id not in user2idx:\n",
        "        return f\"UsuÃ¡rio {user_original_id} nÃ£o encontrado\", []\n",
        "\n",
        "    user_idx = user2idx[user_original_id]\n",
        "\n",
        "    # PrediÃ§Ãµes do modelo\n",
        "    book_indices = torch.tensor(list(range(len(book_ids))), device=device)\n",
        "    user_indices = torch.tensor([user_idx] * len(book_ids), device=device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        cf_scores = model(user_indices, book_indices).cpu().numpy()\n",
        "        cf_scores = cf_scores * (rating_stats['max'] - rating_stats['min']) + rating_stats['min']\n",
        "        cf_scores = np.clip(cf_scores, rating_stats['min'], rating_stats['max'])\n",
        "\n",
        "    # ğŸ¯ ANÃLISE DE POPULARIDADE\n",
        "    book_popularity = df_pandas['book_id'].value_counts().to_dict()\n",
        "    popularity_scores = np.array([book_popularity.get(bid, 0) for bid in book_ids])\n",
        "\n",
        "    if len(popularity_scores) > 0:\n",
        "        pop_percentiles = np.percentile(popularity_scores[popularity_scores > 0], [10, 25, 50, 75, 90])\n",
        "    else:\n",
        "        pop_percentiles = [0, 0, 0, 0, 0]\n",
        "\n",
        "    # ğŸ¯ ESTRATÃ‰GIA DE DIVERSIFICAÃ‡ÃƒO MODERADA\n",
        "    final_scores = cf_scores.copy()\n",
        "\n",
        "    # Penalidade LEVE para super populares\n",
        "    super_popular_mask = popularity_scores >= pop_percentiles[4]  # Top 10%\n",
        "    final_scores[super_popular_mask] -= diversity_strength * 0.3\n",
        "\n",
        "    # Boost MODERADO para gems escondidos\n",
        "    hidden_gems_mask = (popularity_scores <= pop_percentiles[1]) & (popularity_scores > 0)\n",
        "    final_scores[hidden_gems_mask] += discovery_boost * 0.4\n",
        "\n",
        "    # Boost leve para mÃ©dia popularidade\n",
        "    mid_popular_mask = (popularity_scores > pop_percentiles[1]) & (popularity_scores <= pop_percentiles[3])\n",
        "    final_scores[mid_popular_mask] += discovery_boost * 0.2\n",
        "\n",
        "    # Componente de qualidade balanceado (AGORA FUNCIONA)\n",
        "    if quality_scores_dict:\n",
        "        quality_scores = np.array([quality_scores_dict.get(bid, 0.3) for bid in book_ids])\n",
        "        quality_weight = 0.1\n",
        "        final_scores = final_scores * (1 - quality_weight) + quality_scores * quality_weight\n",
        "\n",
        "    # ğŸ¯ FILTRAGEM INTELIGENTE\n",
        "    user_rated_books = set(df_pandas[df_pandas['user_id'] == user_original_id]['book_id'])\n",
        "    valid_mask = [bid not in user_rated_books for bid in book_ids]\n",
        "    valid_indices = np.where(valid_mask)[0]\n",
        "\n",
        "    if len(valid_indices) == 0:\n",
        "        return \"UsuÃ¡rio jÃ¡ avaliou todos os livros disponÃ­veis\", []\n",
        "\n",
        "    # ğŸ¯ CONTROLE DE DIVERSIDADE MODERADO\n",
        "    if 'global_recommendation_count' not in globals():\n",
        "        global global_recommendation_count\n",
        "        global_recommendation_count = Counter()\n",
        "\n",
        "    # Penalidade MUITO mais leve para livros recomendados\n",
        "    for i, book_id in enumerate(book_ids):\n",
        "        current_count = global_recommendation_count.get(book_id, 0)\n",
        "        if current_count > 3:\n",
        "            penalty = current_count * 0.03\n",
        "            final_scores[i] -= penalty\n",
        "\n",
        "    # ğŸ¯ SELEÃ‡ÃƒO MAIS BALANCEADA\n",
        "    candidate_pool_size = min(200, len(valid_indices))\n",
        "    candidate_indices = valid_indices[np.argsort(final_scores[valid_indices])[::-1][:candidate_pool_size]]\n",
        "\n",
        "    # EstratÃ©gia de seleÃ§Ã£o MAIS FLEXÃVEL\n",
        "    selected_indices = []\n",
        "    used_books = set()\n",
        "\n",
        "    # Prioridade 1: Top 2 melhores livros (SEM restriÃ§Ãµes)\n",
        "    top_indices = candidate_indices[:2]\n",
        "    for idx in top_indices:\n",
        "        book_id = book_ids[idx]\n",
        "        if book_id not in used_books:\n",
        "            selected_indices.append(idx)\n",
        "            used_books.add(book_id)\n",
        "\n",
        "    # Prioridade 2: Adicionar 2 livros com boa diversidade\n",
        "    diversity_candidates = []\n",
        "    for idx in candidate_indices[2:]:\n",
        "        book_id = book_ids[idx]\n",
        "        current_count = global_recommendation_count.get(book_id, 0)\n",
        "\n",
        "        # Preferir livros com poucas recomendaÃ§Ãµes, mas nÃ£o exigir zero\n",
        "        if current_count <= 2 and book_id not in used_books:\n",
        "            diversity_candidates.append((idx, current_count, final_scores[idx]))\n",
        "\n",
        "    # Ordenar por poucas recomendaÃ§Ãµes primeiro, depois score\n",
        "    if diversity_candidates:\n",
        "        diversity_candidates.sort(key=lambda x: (x[1], -x[2]))\n",
        "        for idx, count, score in diversity_candidates[:2]:\n",
        "            if len(selected_indices) < 4:\n",
        "                selected_indices.append(idx)\n",
        "                used_books.add(book_ids[idx])\n",
        "\n",
        "    # Prioridade 3: Completar com melhores disponÃ­veis\n",
        "    for idx in candidate_indices:\n",
        "        book_id = book_ids[idx]\n",
        "        if (book_id not in used_books and\n",
        "            len(selected_indices) < top_n):\n",
        "            selected_indices.append(idx)\n",
        "            used_books.add(book_id)\n",
        "\n",
        "    # Garantir que temos exatamente top_n recomendaÃ§Ãµes\n",
        "    if len(selected_indices) < top_n:\n",
        "        remaining = [idx for idx in candidate_indices if idx not in selected_indices]\n",
        "        remaining.sort(key=lambda x: final_scores[x], reverse=True)\n",
        "        selected_indices.extend(remaining[:top_n - len(selected_indices)])\n",
        "\n",
        "    selected_indices = selected_indices[:top_n]\n",
        "\n",
        "    # ğŸ¯ ATUALIZAR CONTAGEM GLOBAL\n",
        "    for book_id in [book_ids[i] for i in selected_indices]:\n",
        "        global_recommendation_count[book_id] = global_recommendation_count.get(book_id, 0) + 1\n",
        "\n",
        "    recommended_books = [book_ids[i] for i in selected_indices]\n",
        "    final_scores_list = [final_scores[i] for i in selected_indices]\n",
        "\n",
        "    return recommended_books, final_scores_list\n",
        "\n",
        "# ğŸ¯ FUNÃ‡ÃƒO PARA ANALISAR DIVERSIDADE REAL\n",
        "def analyze_real_diversity(sample_size=50):\n",
        "    \"\"\"Analisa diversidade real em amostra maior\"\"\"\n",
        "    all_users = list(user2idx.keys())\n",
        "\n",
        "    if len(all_users) < sample_size:\n",
        "        sample_size = len(all_users)\n",
        "\n",
        "    import random\n",
        "    random.seed(42)\n",
        "    test_users = random.sample(all_users, sample_size)\n",
        "\n",
        "    all_recommendations = []\n",
        "    book_frequency = Counter()\n",
        "    user_interests = {}\n",
        "\n",
        "    print(f\"\\nğŸ” ANALISANDO DIVERSIDADE REAL ({sample_size} usuÃ¡rios)...\")\n",
        "\n",
        "    for i, user_id in enumerate(test_users):\n",
        "        if i % 10 == 0:\n",
        "            print(f\"   Progresso: {i}/{sample_size} usuÃ¡rios...\")\n",
        "\n",
        "        recs, scores = hybrid_recommend_books(user_id, top_n=5)\n",
        "\n",
        "        if isinstance(recs, list):\n",
        "            all_recommendations.extend(recs)\n",
        "            book_frequency.update(recs)\n",
        "            interests = detect_user_interests(user_id)\n",
        "            user_interests[user_id] = interests\n",
        "\n",
        "    total_recommendations = len(all_recommendations)\n",
        "    unique_books = len(set(all_recommendations))\n",
        "    diversity_score = unique_books / total_recommendations if total_recommendations > 0 else 0\n",
        "\n",
        "    print(f\"\\nğŸ“Š DIVERSIDADE REAL EM {sample_size} USUÃRIOS:\")\n",
        "    print(f\"   Total de recomendaÃ§Ãµes: {total_recommendations}\")\n",
        "    print(f\"   Livros Ãºnicos: {unique_books}\")\n",
        "    print(f\"   Diversidade: {diversity_score:.3f} ({diversity_score*100:.1f}%)\")\n",
        "\n",
        "    interest_counts = Counter(user_interests.values())\n",
        "    print(f\"\\nğŸ¯ DISTRIBUIÃ‡ÃƒO DE INTERESSES:\")\n",
        "    for interests, count in interest_counts.most_common(10):\n",
        "        print(f\"   {interests}: {count} usuÃ¡rios\")\n",
        "\n",
        "    print(f\"\\nğŸ“š LIVROS MAIS FREQUENTES:\")\n",
        "    for book_id, count in book_frequency.most_common(10):\n",
        "        book_name = book_id_to_title_author.get(book_id, f\"ID {book_id}\")\n",
        "        pop_count = df_pandas[df_pandas['book_id'] == book_id]['book_id'].value_counts().iloc[0] if len(df_pandas[df_pandas['book_id'] == book_id]) > 0 else 0\n",
        "        # ğŸ¯ LINHA SIMPLIFICADA - APENAS CONTAGEM\n",
        "        print(f\"   {book_name}: {count}x ({pop_count} avaliaÃ§Ãµes)\")\n",
        "\n",
        "    return diversity_score\n",
        "\n",
        "# Executar anÃ¡lise de diversidade real\n",
        "real_diversity = analyze_real_diversity(50)\n",
        "\n",
        "# ğŸ¯ VERSÃƒO FINAL DA RECOMENDAÃ‡ÃƒO\n",
        "def recommend_books_with_interests(user_id):\n",
        "    try:\n",
        "        user_id = int(user_id)\n",
        "        recommended_books, scores = hybrid_recommend_books(user_id)\n",
        "\n",
        "        if isinstance(recommended_books, str):\n",
        "            return recommended_books\n",
        "\n",
        "        user_interests = detect_user_interests(user_id)\n",
        "\n",
        "        result = f\"ğŸ¯ PERFIL DETECTADO: {user_interests}\\n\\n\"\n",
        "        result += \"ğŸ“š TOP 5 RECOMENDAÃ‡Ã•ES PERSONALIZADAS:\\n\\n\"\n",
        "\n",
        "        for i, (book_id, score) in enumerate(zip(recommended_books, scores)):\n",
        "            book_info = book_id_to_title_author.get(book_id, f\"Livro ID {book_id}\")\n",
        "            pop_count = df_pandas[df_pandas['book_id'] == book_id]['book_id'].value_counts().iloc[0] if len(df_pandas[df_pandas['book_id'] == book_id]) > 0 else 0\n",
        "\n",
        "            # ğŸ¯ LINHA SIMPLIFICADA - SEM CLASSIFICAÃ‡ÃƒO\n",
        "            result += f\"{i+1}. {book_info}\\n\"\n",
        "            result += f\"   â­ Score: {score:.3f} | {pop_count} avaliaÃ§Ãµes\\n\\n\"\n",
        "\n",
        "        result += f\"ğŸ“Š Sistema com MAE: {best_val_mae:.4f} | Diversidade: {real_diversity*100:.1f}%\"\n",
        "        return result\n",
        "\n",
        "    except ValueError:\n",
        "        return \"âŒ Por favor, digite um ID de usuÃ¡rio vÃ¡lido.\"\n",
        "    except Exception as e:\n",
        "        return f\"âŒ Erro: {str(e)}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8TcFgBHV2fz",
        "outputId": "47756bda-89ce-4035-b3a2-9256a0051802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ” ANALISANDO DIVERSIDADE REAL (50 usuÃ¡rios)...\n",
            "   Progresso: 0/50 usuÃ¡rios...\n",
            "   Progresso: 10/50 usuÃ¡rios...\n",
            "   Progresso: 20/50 usuÃ¡rios...\n",
            "   Progresso: 30/50 usuÃ¡rios...\n",
            "   Progresso: 40/50 usuÃ¡rios...\n",
            "\n",
            "ğŸ“Š DIVERSIDADE REAL EM 50 USUÃRIOS:\n",
            "   Total de recomendaÃ§Ãµes: 250\n",
            "   Livros Ãºnicos: 144\n",
            "   Diversidade: 0.576 (57.6%)\n",
            "\n",
            "ğŸ¯ DISTRIBUIÃ‡ÃƒO DE INTERESSES:\n",
            "   ğŸ§™â€â™‚ï¸ Fantasia Ã‰pica | ğŸ›ï¸ HistÃ³ria & PolÃ­tica | â›ª Literatura Religiosa: 8 usuÃ¡rios\n",
            "   ğŸ§™â€â™‚ï¸ Fantasia Ã‰pica | ğŸ›ï¸ HistÃ³ria & PolÃ­tica | â¤ï¸ Romance ContemporÃ¢neo: 4 usuÃ¡rios\n",
            "   ğŸ§™â€â™‚ï¸ Fantasia Ã‰pica | ğŸ›ï¸ HistÃ³ria & PolÃ­tica | ğŸ˜Š Humor & Graphic Novels: 4 usuÃ¡rios\n",
            "   ğŸ§™â€â™‚ï¸ Fantasia Ã‰pica | â›ª Literatura Religiosa | ğŸ›ï¸ HistÃ³ria & PolÃ­tica: 3 usuÃ¡rios\n",
            "   ğŸ›ï¸ HistÃ³ria & PolÃ­tica | ğŸ§™â€â™‚ï¸ Fantasia Ã‰pica | â›ª Literatura Religiosa: 3 usuÃ¡rios\n",
            "   ğŸ§™â€â™‚ï¸ Fantasia Ã‰pica | ğŸ›ï¸ HistÃ³ria & PolÃ­tica | ğŸ­ Drama & ClÃ¡ssicos: 3 usuÃ¡rios\n",
            "   ğŸ§™â€â™‚ï¸ Fantasia Ã‰pica | ğŸ­ Drama & ClÃ¡ssicos | â›ª Literatura Religiosa: 2 usuÃ¡rios\n",
            "   ğŸ­ Drama & ClÃ¡ssicos | ğŸ›ï¸ HistÃ³ria & PolÃ­tica | â›ª Literatura Religiosa: 2 usuÃ¡rios\n",
            "   ğŸ›ï¸ HistÃ³ria & PolÃ­tica | ğŸ­ Drama & ClÃ¡ssicos | ğŸ§™â€â™‚ï¸ Fantasia Ã‰pica: 2 usuÃ¡rios\n",
            "   ğŸ›ï¸ HistÃ³ria & PolÃ­tica | ğŸ­ Drama & ClÃ¡ssicos | ğŸŒˆ Young Adult: 1 usuÃ¡rios\n",
            "\n",
            "ğŸ“š LIVROS MAIS FREQUENTES:\n",
            "   The Divan - Hafez: 7x (75 avaliaÃ§Ãµes)\n",
            "   ESV Study Bible - Anonymous, Lane T. Dennis, Wayne A. Grudem: 6x (88 avaliaÃ§Ãµes)\n",
            "   Humans of New York: Stories - Brandon Stanton: 5x (102 avaliaÃ§Ãµes)\n",
            "   Mark of the Lion Trilogy - Francine Rivers: 5x (94 avaliaÃ§Ãµes)\n",
            "   Humans of New York - Brandon Stanton: 4x (105 avaliaÃ§Ãµes)\n",
            "   A Game of Thrones: Comic Book, Issue 1 - Daniel Abraham, George R.R. Martin, Tommy Patterson: 4x (144 avaliaÃ§Ãµes)\n",
            "   Attack of the Deranged Mutant Killer Monster Snow Goons - Bill Watterson: 4x (147 avaliaÃ§Ãµes)\n",
            "   The Indispensable Calvin and Hobbes - Bill Watterson: 4x (214 avaliaÃ§Ãµes)\n",
            "   The Complete Calvin and Hobbes - Bill Watterson: 4x (482 avaliaÃ§Ãµes)\n",
            "   Ø§Ù„Ø±Ø­ÙŠÙ‚ Ø§Ù„Ù…Ø®ØªÙˆÙ… - Safiy al-Rahman al-Mubarakfuri: 4x (90 avaliaÃ§Ãµes)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ¯ INTERFACE GRADIO SIMPLIFICADA\n",
        "try:\n",
        "    example_users = list(user2idx.keys())[:min(8, len(user2idx))]\n",
        "    if not example_users:\n",
        "        example_users = [47420, 15744, 49088, 50206]\n",
        "\n",
        "    iface = gr.Interface(\n",
        "        fn=recommend_books_with_interests,\n",
        "        inputs=gr.Number(\n",
        "            label=\"ğŸ”¢ Digite o ID do usuÃ¡rio\",\n",
        "            placeholder=\"Ex: 47420, 15744, 49088...\",\n",
        "            precision=0\n",
        "        ),\n",
        "        outputs=gr.Textbox(\n",
        "            label=\"ğŸ“– RecomendaÃ§Ãµes Personalizadas\",\n",
        "            lines=14\n",
        "        ),\n",
        "        title=\"ğŸ¯ Sistema de RecomendaÃ§Ã£o Inteligente\",\n",
        "        description=f\"\"\"\\\n",
        "ğŸ“Š **Sistema de RecomendaÃ§Ã£o Baseado em ConteÃºdo e Colaborativo**\n",
        "âœ… MAE: {best_val_mae:.4f} | ğŸ‘¥ {len(user2idx):,} usuÃ¡rios | ğŸ“š {len(book2idx):,} livros\n",
        "ğŸ¯ Diversidade medida: {real_diversity*100:.1f}%\n",
        "        \"\"\",\n",
        "        examples=[[uid] for uid in example_users]\n",
        "    )\n",
        "\n",
        "    print(f\"\\nğŸš€ Iniciando interface com diversidade: {real_diversity*100:.1f}%\")\n",
        "    iface.launch(share=False)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Erro: {e}\")"
      ],
      "metadata": {
        "id": "dFqawkOLYoG8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "outputId": "c125a85a-76d3-4512-b7a4-932858b5c600"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸš€ Iniciando interface com diversidade: 57.6%\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7861, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ“Š Resultados e AnÃ¡lise\n",
        "\n",
        "### ğŸ¯ MÃ©tricas de Desempenho\n",
        "\n",
        "| MÃ©trica | Valor Esperado | Significado |\n",
        "|---------|----------------|-------------|\n",
        "| **MAE** | 0.6-0.8 | PrecisÃ£o das prediÃ§Ãµes |\n",
        "| **Diversidade** | 70-80% | Variedade de recomendaÃ§Ãµes |\n",
        "| **Coverage** | Alto | Amplitude do catÃ¡logo |\n",
        "\n",
        "### ğŸ” AnÃ¡lise de Diversidade Real\n",
        "\n",
        "```python\n",
        "def analyze_real_diversity(sample_size=50):\n",
        "    # Testa 50 usuÃ¡rios e analisa sobreposiÃ§Ã£o\n",
        "    diversity_score = unique_books / total_recommendations\n",
        "```\n",
        "\n",
        "**Exemplo de SaÃ­da**:\n",
        "```\n",
        "ğŸ“Š DIVERSIDADE REAL EM 50 USUÃRIOS:\n",
        "   Total de recomendaÃ§Ãµes: 250\n",
        "   Livros Ãºnicos: 200\n",
        "   Diversidade: 0.800 (80.0%)\n",
        "```\n",
        "\n",
        "### ğŸ¨ Interface de UsuÃ¡rio\n",
        "\n",
        "A interface Gradio permite:\n",
        "- ğŸ”¢ **Input de ID de usuÃ¡rio**\n",
        "- ğŸ“– **RecomendaÃ§Ãµes personalizadas**\n",
        "- ğŸ¯ **Perfil detectado automaticamente**\n",
        "- â­ **Scores explicativos**\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ† ConclusÃµes e InovaÃ§Ãµes\n",
        "\n",
        "### âœ… Pontos Fortes do Sistema\n",
        "\n",
        "1. **ğŸ¯ PrecisÃ£o**: CombinaÃ§Ã£o otimizada de tÃ©cnicas\n",
        "2. **ğŸ”„ Diversidade**: Mecanismos anti-repetiÃ§Ã£o\n",
        "3. **ğŸ“š Descoberta**: Incentivo a livros menos conhecidos\n",
        "4. **âš¡ Performance**: Otimizado para GPU\n",
        "\n",
        "### ğŸ“ˆ Impacto Esperado\n",
        "\n",
        "> \"Este sistema nÃ£o apenas recomenda livros populares, mas **descobre tesouros escondidos** enquanto mantÃ©m alta relevÃ¢ncia personalizada para cada usuÃ¡rio.\"\n"
      ],
      "metadata": {
        "id": "ilOeOSl-EXaX"
      }
    }
  ]
}